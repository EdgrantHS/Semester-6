Here's a cheatsheet for an AI class, based on the slides you uploaded:


**5. Bias-Variance Tradeoff**

* **High Bias:** The model performs poorly on training data; adding more features may help. [cite: 980, 981]
* **High Variance:** The model performs well on training data but poorly on unseen data; removing features or obtaining more data may help. [cite: 980, 981]

**6. Correctness**

* **Confusion Matrix:** A table used to evaluate the performance of a classification model. [cite: 928]
* **Key Terms:**
    * **True Positive:** Correctly predicted positive case. [cite: 988]
    * **False Positive (Type I Error):** Incorrectly predicted positive case. [cite: 988]
    * **False Negative (Type II Error):** Incorrectly predicted negative case. [cite: 988]
    * **True Negative:** Correctly predicted negative case. [cite: 988]
* **ROC Curve:** A graph showing the performance of a classification model at all classification thresholds. [cite: 991, 992]
* **AUC (Area Under the ROC Curve):** A measure of the overall performance of a classification model. [cite: 994]


**Regression**

* **Purpose:** To analyze the relationship between a dependent variable and one or more independent variables. [cite: 627, 628, 629, 630] It's used for predicting continuous values. [cite: 638, 639]
* **Types:**
    * **Simple Linear Regression:** One independent variable. [cite: 628, 629]
    * **Multiple Linear Regression:** More than one independent variable. [cite: 628, 629, 630]
* **Key Terms:**
    * Independent variable (X): Predictor. [cite: 632, 633]
    * Dependent variable (Y): Response. [cite: 632, 633]
    * Coefficient: The slope of the line. [cite: 632, 633]
    * Intercept: The point where the line crosses the Y-axis. [cite: 632, 633]
    * Residuals: The difference between the observed and predicted values. [cite: 632, 633]

**Classification**

* **Purpose:** Supervised learning approach to categorize items into discrete classes. [cite: 1362, 1363, 1364] Algorithms learn the relationship between feature variables and a target variable to predict class labels. [cite: 1363, 1364]
* **Types:**
    * **Binary Classification:** Two categories (e.g., defaulter/non-defaulter). [cite: 1376, 1377, 1378]
    * **Multi-class Classification:** More than two categories (e.g., drug types). [cite: 1376, 1377, 1378]
* **Use Cases:**
    * Loan default prediction. [cite: 1370, 1371, 1372, 1373, 1374, 1375]
    * Churn detection (predicting customer attrition). [cite: 1387, 1388, 1389]
    * Predicting customer response to advertising. [cite: 1387, 1388, 1389]

**Clustering**

* **Purpose:** Unsupervised learning technique to group similar data points into clusters. [cite: 289, 290, 291, 292, 293, 294]
* **Characteristics of a Cluster:** Data points within a cluster are similar to each other and dissimilar to data points in other clusters. [cite: 310, 311, 312]
* **Use Cases:** Customer segmentation (grouping customers based on similarity, such as age, gender, spending habits). [cite: 279, 280, 281, 282, 283, 284, 285, 286, 287, 288, 289, 290, 291, 292, 293, 294, 295, 296, 297, 298, 299, 300, 301, 302, 303, 304, 305, 306, 307, 308, 309]